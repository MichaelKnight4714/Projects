{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "# import the code that cleans the hydrated tweets\n",
    "from hydration_cleaner import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "harvey = pd.read_json('../data/harvey_hy.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14970"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(harvey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from https://stackoverflow.com/questions/21058935/python-json-loads-shows-valueerror-extra-data/51830719\n",
    "#read in json from hydrator\n",
    "tweets = []\n",
    "for line in open('../data/harvey_hy.json', 'r'):\n",
    "    tweets.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14970"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-bf6137df1a9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mharvey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpost_hydration_clean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mharvey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/DSI/Submissions/projects/project_5b/Mapping/hydration_cleaner.py\u001b[0m in \u001b[0;36mpost_hydration_clean\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m              \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'place_coordinates'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m              \u001b[0mlat1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'place_coordinates'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m              \u001b[0mlong1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'place_coordinates'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "harvey = post_hydration_clean(harvey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harvey#.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>901595110210723840</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>901595105680916482</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>901595104321921025</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>901595098626093056</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>901595097887686656</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id  label\n",
       "0  901595110210723840      0\n",
       "1  901595105680916482      2\n",
       "2  901595104321921025      0\n",
       "3  901595098626093056      2\n",
       "4  901595097887686656      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in csv file of scored tweets\n",
    "csv_file = pd.DataFrame(pd.read_csv(\"../data/harvey_scored.csv\", sep = \",\", header = 0, index_col = False))\n",
    "#tweetid and label\n",
    "tweet_id = csv_file[['id','label']]\n",
    "tweet_id = pd.DataFrame(tweet_id)\n",
    "#set to dataframe\n",
    "tweet_id.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(csv_file)#['lat'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>901595110210723840</td>\n",
       "      <td>29.7604</td>\n",
       "      <td>-95.3698</td>\n",
       "      <td>harvey broke our neighbor s tree  one younger ...</td>\n",
       "      <td>harvey broke our neighbor s tree one younger b...</td>\n",
       "      <td>harvey broke our neighbor s tree one younger b...</td>\n",
       "      <td>harvey broke our neighbor s tree one younger b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>901595105680916482</td>\n",
       "      <td>29.7604</td>\n",
       "      <td>-95.3698</td>\n",
       "      <td>hurricane harvey could unleash 3 feet of rain ...</td>\n",
       "      <td>hurricane harvey could unleash 3 feet of rain ...</td>\n",
       "      <td>hurricane harvey could unleash 3 foot of rain ...</td>\n",
       "      <td>hurrican harvey could unleash 3 feet of rain a...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>901595104321921025</td>\n",
       "      <td>29.7604</td>\n",
       "      <td>-95.3698</td>\n",
       "      <td>7 pm briefing to begin day 2 of 12 hr harvey o...</td>\n",
       "      <td>7 pm briefing to begin day 2 of 12 hr harvey o...</td>\n",
       "      <td>7 pm briefing to begin day 2 of 12 hr harvey o...</td>\n",
       "      <td>7 pm brief to begin day 2 of 12 hr harvey op h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>901595098626093056</td>\n",
       "      <td>29.7604</td>\n",
       "      <td>-95.3698</td>\n",
       "      <td>damn i m late on this hurricane</td>\n",
       "      <td>damn i m late on this hurricane</td>\n",
       "      <td>damn i m late on this hurricane</td>\n",
       "      <td>damn i m late on thi hurrican</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>901595097887686656</td>\n",
       "      <td>29.7604</td>\n",
       "      <td>-95.3698</td>\n",
       "      <td>lmao dude on the hurricane harvey snap story h...</td>\n",
       "      <td>lmao dude on the hurricane harvey snap story h...</td>\n",
       "      <td>lmao dude on the hurricane harvey snap story h...</td>\n",
       "      <td>lmao dude on the hurrican harvey snap stori ha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id      lat     long  \\\n",
       "0  901595110210723840  29.7604 -95.3698   \n",
       "1  901595105680916482  29.7604 -95.3698   \n",
       "2  901595104321921025  29.7604 -95.3698   \n",
       "3  901595098626093056  29.7604 -95.3698   \n",
       "4  901595097887686656  29.7604 -95.3698   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  harvey broke our neighbor s tree  one younger ...   \n",
       "1  hurricane harvey could unleash 3 feet of rain ...   \n",
       "2  7 pm briefing to begin day 2 of 12 hr harvey o...   \n",
       "3                    damn i m late on this hurricane   \n",
       "4  lmao dude on the hurricane harvey snap story h...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  harvey broke our neighbor s tree one younger b...   \n",
       "1  hurricane harvey could unleash 3 feet of rain ...   \n",
       "2  7 pm briefing to begin day 2 of 12 hr harvey o...   \n",
       "3                    damn i m late on this hurricane   \n",
       "4  lmao dude on the hurricane harvey snap story h...   \n",
       "\n",
       "                                          lemmatized  \\\n",
       "0  harvey broke our neighbor s tree one younger b...   \n",
       "1  hurricane harvey could unleash 3 foot of rain ...   \n",
       "2  7 pm briefing to begin day 2 of 12 hr harvey o...   \n",
       "3                    damn i m late on this hurricane   \n",
       "4  lmao dude on the hurricane harvey snap story h...   \n",
       "\n",
       "                                             stemmed  label  \n",
       "0  harvey broke our neighbor s tree one younger b...      0  \n",
       "1  hurrican harvey could unleash 3 feet of rain a...      2  \n",
       "2  7 pm brief to begin day 2 of 12 hr harvey op h...      0  \n",
       "3                      damn i m late on thi hurrican      2  \n",
       "4  lmao dude on the hurrican harvey snap stori ha...      1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harvey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #from https://stackoverflow.com/questions/35864007/python-3-5-iterate-through-a-list-of-dictionaries\n",
    "# #take gridbox coordinates from json\n",
    "# box = []\n",
    "# for index in range(len(tweets)):\n",
    "#     try:\n",
    "#         for each in tweets[index]['place']['bounding_box']['coordinates']:\n",
    "#             box.append(each)\n",
    "#     # if no coordinates write 0s\n",
    "#     except:\n",
    "#         box.append([[0, 0],[0, 0],[0, 0],[0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harvey = harvey['final_coordinates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harvey.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #from https://docs.python.org/3/tutorial/datastructures.html\n",
    "# # coordinates if tweet has coordinates as a list\n",
    "# cords = []\n",
    "# cd = []\n",
    "# for index in range(len(tweets)):\n",
    "#     cd = []\n",
    "#     try:\n",
    "#         for each in tweets[index]['coordinates']['coordinates']:\n",
    "#             cd.append(each)\n",
    "#         cords.append(cd)\n",
    "#     except:\n",
    "#         cords.append([0,0])\n",
    "# #make cords dataframr        \n",
    "# cords = pd.DataFrame(cords)\n",
    "# cords = cords.rename(columns ={0:'lon_c', 1:'lat_c'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for i in range(len(harvey)):\n",
    "    df['lat_g'] = harvey['final_coordinates'][i][0]\n",
    "    df['lon_g'] = harvey['final_coordinates'][i][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(harvey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get center of the the gridbox for each tweet\n",
    "latitude = []\n",
    "longitude = []\n",
    "for i in range(len(box)):\n",
    "    lon = (box[i][0][0] + box[i][1][0] + box[i][2][0] + box[i][3][0]) / 4\n",
    "    lat = (box[i][0][1] + box[i][1][1] + box[i][2][1] + box[i][3][1]) / 4\n",
    "    latitude.append(lat)\n",
    "    longitude.append(lon)\n",
    "    #add to dataframe\n",
    "    df = pd.DataFrame({'lat_g': latitude, \"lon_g\":longitude}, columns =['lat_g', 'lon_g']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine dataframes\n",
    "points = pd.concat([tweet_id,df,cords], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if tweet has coordinates add to a column \n",
    "#if not add the center grid coordinates\n",
    "var =[]\n",
    "for item in points['lon_c'].items():\n",
    "    if item[1] != 0.0:\n",
    "         var.append(item[1])\n",
    "    else:\n",
    "        var.append(points['lon_g'].iloc[item[0]])\n",
    "#add to a dataframe\n",
    "var = pd.DataFrame({'lon': var}, columns =['lon']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if tweet has coordinates add to a column \n",
    "#if not add the center grid coordinates\n",
    "var_2 = []\n",
    "for item in points['lat_c'].items():\n",
    "    if item[1] != 0.0:\n",
    "        var_2.append(item[1])\n",
    "    else:\n",
    "        var_2.append(points['lat_g'].iloc[item[0]])\n",
    "#add to a dataframe\n",
    "var_2 = pd.DataFrame({'lat': var_2}, columns =['lat']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #combine to one dataframe\n",
    "# point = pd.concat([points, var, var_2], axis=1)\n",
    "# #export to csv\n",
    "# point.to_csv('./test.csv')\n",
    "# point.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from https://towardsdatascience.com/geopandas-101-plot-any-data-with-a-latitude-and-longitude-on-a-map-98e01944b972\n",
    "#import\n",
    "import matplotlib.pyplot as plt\n",
    "import descartes\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "%matplotlib inline\n",
    "crs ={'init': 'epsg:4326'}\n",
    "file_path = '/Users/michaelknight/Downloads/states_21basic/states.shx'\n",
    "map_df = gpd.read_file(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set points for geopandas\n",
    "geometry = [Point(xy) for xy in zip(point['lon'], \n",
    "                                    point['lat'])]\n",
    "geo = gpd.GeoDataFrame(point,\n",
    "                         crs =crs,\n",
    "                         geometry = geometry)\n",
    "#remove points with no coordinates\n",
    "test_df = geo.lon != 0.0\n",
    "geo_df = geo[test_df]\n",
    "#check dataframe\n",
    "geo_df.head()\n",
    "l_count = geo_df.label.value_counts()\n",
    "l_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from\n",
    "\n",
    "#set up plot\n",
    "fig, ax = plt.subplots(figsize=(25, 25))\n",
    "#add US map\n",
    "#from Nick Minaie\n",
    "#title\n",
    "plt.title('Hurricane Harvey Tweets 8/24/2017 - 8/27/2017', size=40)\n",
    "map_df[(map_df['DRAWSEQ']<51) & (map_df['DRAWSEQ']>=2)].plot(                                                    \n",
    "             color='lightgray',      # Colormap for the states                     \n",
    "             linewidth=0.4,      # line width for state borders\n",
    "             ax=ax,              # plotting the map on 'ax'\n",
    "             edgecolor='black');\n",
    "# off topic tweets\n",
    "geo_df[geo_df['label'] == 0].plot(ax = ax, markersize = 50, color = 'black', marker = 'o', label = f'Off Topic Tweets {l_count[0]}')\n",
    "# on topic tweets non urgent\n",
    "geo_df[geo_df['label'] == 1].plot(ax = ax, markersize = 50, color = 'yellow', marker = 'o', label = f'Low-Urgent Tweets {l_count[1]}')\n",
    "#on topic tweets urgent\n",
    "geo_df[geo_df['label'] == 2].plot(ax = ax, markersize = 50, color = 'orange', marker = 'o', label = f'High-Urgent Tweets {l_count[2]}')\n",
    "#set limit of lat and lon\n",
    "plt.xlim(geo_df['lon'].min()-1.1, geo_df['lon'].max() + 1.1)\n",
    "plt.ylim(geo_df['lat'].min()-1.1, geo_df['lat'].max() + 1.1)\n",
    "#axis labels\n",
    "plt.xlabel('Longitude', size = 30)\n",
    "plt.ylabel('Latitude', size = 30)\n",
    "#add legend\n",
    "plt.xticks(fontsize = 20)\n",
    "plt.yticks(fontsize =20)\n",
    "plt.legend(prop = {'size':25})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "#size 2s\n",
    "two_df = geo_df['label'] == 2\n",
    "two_df = geo_df[two_df]\n",
    "# test_df = two_df.lon != 0.0\n",
    "# two_df = two_df[test_df]\n",
    "#size 1s\n",
    "one_df = geo_df['label'] == 1\n",
    "one_df = geo_df[one_df]\n",
    "# test_df = one_df.lon != 0.0\n",
    "# one_df = one_df[test_df]\n",
    "\n",
    "#https://www.bigendiandata.com/2017-06-27-Mapping_in_Jupyter/\n",
    "a = two_df['lon']\n",
    "b = two_df['lat']\n",
    "count = Counter(zip(a,b))\n",
    "# create a list of the sizes, here multiplied by 10 for scale\n",
    "size = [10*count[(aa,bb)] for aa,bb in zip(a,b)]\n",
    "\n",
    "two_df['size']=size\n",
    "\n",
    "#https://www.bigendiandata.com/2017-06-27-Mapping_in_Jupyter/\n",
    "x = one_df['lon'] \n",
    "y = one_df['lat']\n",
    "c = Counter(zip(x,y))\n",
    "# create a list of the sizes, here multiplied by 10 for scale\n",
    "s = [10*c[(xx,yy)] for xx,yy in zip(x,y)]\n",
    "one_df['size'] = s\n",
    "new_df = pd.concat([one_df, two_df], axis=0)\n",
    "\n",
    "# merge 1s and 2s\n",
    "new_df = pd.concat([one_df, two_df], axis=0)\n",
    "new_df.head()\n",
    "\n",
    "#plot\n",
    "fig, ax = plt.subplots(figsize=(25, 25))\n",
    "plt.title('Hurricane Harvey on Topic Tweets 8/24/2017 - 8/27/2017', size=40)\n",
    "map_df[(map_df['DRAWSEQ']<51) & (map_df['DRAWSEQ']>=2)].plot(                                                    \n",
    "             color='lightgray',      # Colormap for the states                     \n",
    "             linewidth=0.4,      # line width for state borders\n",
    "             ax=ax,              # plotting the map on 'ax'\n",
    "             edgecolor='black');\n",
    "#low-urgent tweets ploted as size = 10xthe number of tweets from that location\n",
    "new_df[new_df['label'] == 1].plot(ax = ax, markersize = (new_df['size']), color = 'yellow', marker = 'o', alpha ='0.7', label = f'Low-Urgent Tweets {l_count[1]}')\n",
    "#low-urgent tweets ploted as size = 10xthe number of tweets from that location\n",
    "new_df[new_df['label'] == 2].plot(ax = ax, markersize = (new_df['size']), color = 'orange', marker = 'o', alpha = '0.7', label = f'High-Urgent Tweets {l_count[2]}')\n",
    "#set limit of lat and lon\n",
    "plt.xlim(new_df['lon'].min()-1.1, new_df['lon'].max() + 1.1)\n",
    "plt.ylim(new_df['lat'].min()-1.1, new_df['lat'].max() + 1.1)\n",
    "plt.xlabel('Longitude', size = 30)\n",
    "plt.ylabel('Latitude', size = 30)\n",
    "#add legend\n",
    "plt.xticks(fontsize = 20)\n",
    "plt.yticks(fontsize =20)\n",
    "plt.legend(prop = {'size':30})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "fig, ax = plt.subplots(figsize=(25, 25))\n",
    "plt.title('Hurricane Harvey on Topic Tweets 8/24/2017 - 8/27/2017', size=40)\n",
    "map_df[(map_df['DRAWSEQ']<51) & (map_df['DRAWSEQ']>=2)].plot(                                                    \n",
    "             color='lightgray',      # Colormap for the states                     \n",
    "             linewidth=0.4,      # line width for state borders\n",
    "             ax=ax,              # plotting the map on 'ax'\n",
    "             edgecolor='black');\n",
    "#low-urgent tweets ploted as size = 10xthe number of tweets from that location\n",
    "new_df[new_df['label'] == 1].plot(ax = ax, markersize = (new_df['size']), color = 'yellow', marker = 'o', alpha ='0.7', label = f'Low-Urgent Tweets {l_count[1]}')\n",
    "#low-urgent tweets ploted as size = 10xthe number of tweets from that location\n",
    "new_df[new_df['label'] == 2].plot(ax = ax, markersize = (new_df['size']), color = 'orange', marker = 'o', alpha = '0.7', label = f'High-Urgent Tweets {l_count[2]}')\n",
    "#set limit of lat and lon\n",
    "plt.xlim(-125,-65)\n",
    "plt.ylim(20,55)\n",
    "plt.xlabel('Longitude', size = 30)\n",
    "plt.ylabel('Latitude', size = 30)\n",
    "#add legend\n",
    "plt.xticks(fontsize = 20)\n",
    "plt.yticks(fontsize =20)\n",
    "plt.legend(prop = {'size':30})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
